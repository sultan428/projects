{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing needed libraries and models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier,AdaBoostClassifier,BaggingClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and pre processing the two approuches datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approuch 1 preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_mmr</th>\n",
       "      <th>num_mmr</th>\n",
       "      <th>tot_intel</th>\n",
       "      <th>tot_stren</th>\n",
       "      <th>tot_agi</th>\n",
       "      <th>tot_range</th>\n",
       "      <th>tot_melee</th>\n",
       "      <th>radiant</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>lobby_type_Normal</th>\n",
       "      <th>lobby_type_Ranked</th>\n",
       "      <th>lobby_type_practise</th>\n",
       "      <th>game_mode_All_Draft</th>\n",
       "      <th>game_mode_All_Random</th>\n",
       "      <th>game_mode_Captains_Draft</th>\n",
       "      <th>game_mode_Captains_mode</th>\n",
       "      <th>game_mode_Least_played</th>\n",
       "      <th>game_mode_Random_Draft</th>\n",
       "      <th>game_mode_Single_Draft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4257</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4147</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4811</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3148</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4261</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_mmr  num_mmr  tot_intel  tot_stren  tot_agi  tot_range  tot_melee  \\\n",
       "0     4257        2          1          3        1          1          4   \n",
       "2     4147        5          1          3        1          1          4   \n",
       "4     4811        6          2          1        2          3          2   \n",
       "6     3148        3          3          1        1          3          2   \n",
       "8     4261        5          1          2        2          2          3   \n",
       "\n",
       "   radiant  day_of_week  month           ...            lobby_type_Normal  \\\n",
       "0        1            0      8           ...                            0   \n",
       "2        1            0      8           ...                            0   \n",
       "4        1            0      8           ...                            0   \n",
       "6        1            0      8           ...                            0   \n",
       "8        1            0      8           ...                            0   \n",
       "\n",
       "   lobby_type_Ranked  lobby_type_practise  game_mode_All_Draft  \\\n",
       "0                  1                    0                    1   \n",
       "2                  1                    0                    0   \n",
       "4                  1                    0                    1   \n",
       "6                  1                    0                    1   \n",
       "8                  1                    0                    1   \n",
       "\n",
       "   game_mode_All_Random  game_mode_Captains_Draft  game_mode_Captains_mode  \\\n",
       "0                     0                         0                        0   \n",
       "2                     0                         0                        0   \n",
       "4                     0                         0                        0   \n",
       "6                     0                         0                        0   \n",
       "8                     0                         0                        0   \n",
       "\n",
       "   game_mode_Least_played  game_mode_Random_Draft  game_mode_Single_Draft  \n",
       "0                       0                       0                       0  \n",
       "2                       0                       1                       0  \n",
       "4                       0                       0                       0  \n",
       "6                       0                       0                       0  \n",
       "8                       0                       0                       0  \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the approuch one dataset\n",
    "app1 = pd.read_csv('app1')\n",
    "# taking the radiant team only, so the model dont be sensitive to the second team\n",
    "app1 = app1.loc[app1.radiant == 1]\n",
    "app1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_mmr</th>\n",
       "      <th>num_mmr</th>\n",
       "      <th>tot_intel</th>\n",
       "      <th>tot_stren</th>\n",
       "      <th>tot_agi</th>\n",
       "      <th>tot_range</th>\n",
       "      <th>tot_melee</th>\n",
       "      <th>radiant</th>\n",
       "      <th>Juggernaut</th>\n",
       "      <th>Axe</th>\n",
       "      <th>...</th>\n",
       "      <th>lobby_type_Normal</th>\n",
       "      <th>lobby_type_Ranked</th>\n",
       "      <th>lobby_type_practise</th>\n",
       "      <th>game_mode_All_Draft</th>\n",
       "      <th>game_mode_All_Random</th>\n",
       "      <th>game_mode_Captains_Draft</th>\n",
       "      <th>game_mode_Captains_mode</th>\n",
       "      <th>game_mode_Least_played</th>\n",
       "      <th>game_mode_Random_Draft</th>\n",
       "      <th>game_mode_Single_Draft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4257</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4147</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4811</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3148</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4261</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_mmr  num_mmr  tot_intel  tot_stren  tot_agi  tot_range  tot_melee  \\\n",
       "0     4257        2          1          3        1          1          4   \n",
       "2     4147        5          1          3        1          1          4   \n",
       "4     4811        6          2          1        2          3          2   \n",
       "6     3148        3          3          1        1          3          2   \n",
       "8     4261        5          1          2        2          2          3   \n",
       "\n",
       "   radiant  Juggernaut  Axe           ...            lobby_type_Normal  \\\n",
       "0        1           1    0           ...                            0   \n",
       "2        1           0    1           ...                            0   \n",
       "4        1           0    1           ...                            0   \n",
       "6        1           0    0           ...                            0   \n",
       "8        1           0    0           ...                            0   \n",
       "\n",
       "   lobby_type_Ranked  lobby_type_practise  game_mode_All_Draft  \\\n",
       "0                  1                    0                    1   \n",
       "2                  1                    0                    0   \n",
       "4                  1                    0                    1   \n",
       "6                  1                    0                    1   \n",
       "8                  1                    0                    1   \n",
       "\n",
       "   game_mode_All_Random  game_mode_Captains_Draft  game_mode_Captains_mode  \\\n",
       "0                     0                         0                        0   \n",
       "2                     0                         0                        0   \n",
       "4                     0                         0                        0   \n",
       "6                     0                         0                        0   \n",
       "8                     0                         0                        0   \n",
       "\n",
       "   game_mode_Least_played  game_mode_Random_Draft  game_mode_Single_Draft  \n",
       "0                       0                       0                       0  \n",
       "2                       0                       1                       0  \n",
       "4                       0                       0                       0  \n",
       "6                       0                       0                       0  \n",
       "8                       0                       0                       0  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting target and featuresnapprouch one\n",
    "y_app1 = app1.radiant_win_True\n",
    "X_app1 = app1.drop(labels=['radiant_win_True','day_of_week',\n",
    "                           'month','week','hour','match_id'],axis=1)\n",
    "\n",
    "X_app1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train_app1, X_test_app1, y_train_app1, y_test_app1 = train_test_split(X_app1,y_app1,test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standerizing the dataframe\n",
    "scale = StandardScaler()\n",
    "# fitting and transforming the train data set\n",
    "X_train_app1 = scale.fit_transform(X_train_app1)\n",
    "# transforming the test set\n",
    "X_test_app1 = scale.transform(X_test_app1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approuch two preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_mmr</th>\n",
       "      <th>diff_intel</th>\n",
       "      <th>diff_stren</th>\n",
       "      <th>diff_agi</th>\n",
       "      <th>diff_range</th>\n",
       "      <th>diff_melee</th>\n",
       "      <th>match_id</th>\n",
       "      <th>radiant_win_True</th>\n",
       "      <th>dire_plyr_1_Abaddon</th>\n",
       "      <th>dire_plyr_1_Alchemist</th>\n",
       "      <th>...</th>\n",
       "      <th>rad_plyr_5_Venomancer</th>\n",
       "      <th>rad_plyr_5_Viper</th>\n",
       "      <th>rad_plyr_5_Visage</th>\n",
       "      <th>rad_plyr_5_Warlock</th>\n",
       "      <th>rad_plyr_5_Weaver</th>\n",
       "      <th>rad_plyr_5_Windranger</th>\n",
       "      <th>rad_plyr_5_Winter Wyvern</th>\n",
       "      <th>rad_plyr_5_Witch Doctor</th>\n",
       "      <th>rad_plyr_5_Wraith King</th>\n",
       "      <th>rad_plyr_5_Zeus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4257</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-4</td>\n",
       "      <td>3300000109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4147</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-4</td>\n",
       "      <td>3300000200</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4811</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>3300000206</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3148</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>3300000404</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4261</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>3300000405</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_mmr  diff_intel  diff_stren  diff_agi  diff_range  diff_melee  \\\n",
       "0     4257          -1           2        -1          -2          -4   \n",
       "1     4147           0          -1         1           0          -4   \n",
       "2     4811          -1           0         1           0          -2   \n",
       "3     3148           3          -1        -2           1          -2   \n",
       "4     4261           0          -1         1           0          -3   \n",
       "\n",
       "     match_id  radiant_win_True  dire_plyr_1_Abaddon  dire_plyr_1_Alchemist  \\\n",
       "0  3300000109                 0                    0                      0   \n",
       "1  3300000200                 1                    0                      0   \n",
       "2  3300000206                 1                    0                      0   \n",
       "3  3300000404                 1                    0                      0   \n",
       "4  3300000405                 0                    0                      0   \n",
       "\n",
       "        ...         rad_plyr_5_Venomancer  rad_plyr_5_Viper  \\\n",
       "0       ...                             0                 0   \n",
       "1       ...                             0                 0   \n",
       "2       ...                             0                 0   \n",
       "3       ...                             0                 0   \n",
       "4       ...                             0                 0   \n",
       "\n",
       "   rad_plyr_5_Visage  rad_plyr_5_Warlock  rad_plyr_5_Weaver  \\\n",
       "0                  0                   0                  0   \n",
       "1                  0                   0                  0   \n",
       "2                  0                   0                  0   \n",
       "3                  0                   0                  0   \n",
       "4                  0                   0                  0   \n",
       "\n",
       "   rad_plyr_5_Windranger  rad_plyr_5_Winter Wyvern  rad_plyr_5_Witch Doctor  \\\n",
       "0                      0                         0                        0   \n",
       "1                      0                         0                        0   \n",
       "2                      0                         0                        0   \n",
       "3                      0                         0                        0   \n",
       "4                      0                         0                        0   \n",
       "\n",
       "   rad_plyr_5_Wraith King  rad_plyr_5_Zeus  \n",
       "0                       0                0  \n",
       "1                       0                0  \n",
       "2                       0                0  \n",
       "3                       0                0  \n",
       "4                       0                0  \n",
       "\n",
       "[5 rows x 1138 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading approuch two data set\n",
    "app2= pd.read_csv('app2')\n",
    "app2.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_mmr</th>\n",
       "      <th>diff_intel</th>\n",
       "      <th>diff_stren</th>\n",
       "      <th>diff_agi</th>\n",
       "      <th>diff_range</th>\n",
       "      <th>diff_melee</th>\n",
       "      <th>dire_plyr_1_Abaddon</th>\n",
       "      <th>dire_plyr_1_Alchemist</th>\n",
       "      <th>dire_plyr_1_Ancient Apparition</th>\n",
       "      <th>dire_plyr_1_Anti-Mage</th>\n",
       "      <th>...</th>\n",
       "      <th>rad_plyr_5_Venomancer</th>\n",
       "      <th>rad_plyr_5_Viper</th>\n",
       "      <th>rad_plyr_5_Visage</th>\n",
       "      <th>rad_plyr_5_Warlock</th>\n",
       "      <th>rad_plyr_5_Weaver</th>\n",
       "      <th>rad_plyr_5_Windranger</th>\n",
       "      <th>rad_plyr_5_Winter Wyvern</th>\n",
       "      <th>rad_plyr_5_Witch Doctor</th>\n",
       "      <th>rad_plyr_5_Wraith King</th>\n",
       "      <th>rad_plyr_5_Zeus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4257</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4147</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4811</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3148</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4261</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_mmr  diff_intel  diff_stren  diff_agi  diff_range  diff_melee  \\\n",
       "0     4257          -1           2        -1          -2          -4   \n",
       "1     4147           0          -1         1           0          -4   \n",
       "2     4811          -1           0         1           0          -2   \n",
       "3     3148           3          -1        -2           1          -2   \n",
       "4     4261           0          -1         1           0          -3   \n",
       "\n",
       "   dire_plyr_1_Abaddon  dire_plyr_1_Alchemist  dire_plyr_1_Ancient Apparition  \\\n",
       "0                    0                      0                               0   \n",
       "1                    0                      0                               0   \n",
       "2                    0                      0                               0   \n",
       "3                    0                      0                               0   \n",
       "4                    0                      0                               0   \n",
       "\n",
       "   dire_plyr_1_Anti-Mage       ...         rad_plyr_5_Venomancer  \\\n",
       "0                      0       ...                             0   \n",
       "1                      0       ...                             0   \n",
       "2                      0       ...                             0   \n",
       "3                      0       ...                             0   \n",
       "4                      0       ...                             0   \n",
       "\n",
       "   rad_plyr_5_Viper  rad_plyr_5_Visage  rad_plyr_5_Warlock  rad_plyr_5_Weaver  \\\n",
       "0                 0                  0                   0                  0   \n",
       "1                 0                  0                   0                  0   \n",
       "2                 0                  0                   0                  0   \n",
       "3                 0                  0                   0                  0   \n",
       "4                 0                  0                   0                  0   \n",
       "\n",
       "   rad_plyr_5_Windranger  rad_plyr_5_Winter Wyvern  rad_plyr_5_Witch Doctor  \\\n",
       "0                      0                         0                        0   \n",
       "1                      0                         0                        0   \n",
       "2                      0                         0                        0   \n",
       "3                      0                         0                        0   \n",
       "4                      0                         0                        0   \n",
       "\n",
       "   rad_plyr_5_Wraith King  rad_plyr_5_Zeus  \n",
       "0                       0                0  \n",
       "1                       0                0  \n",
       "2                       0                0  \n",
       "3                       0                0  \n",
       "4                       0                0  \n",
       "\n",
       "[5 rows x 1136 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting target and features\n",
    "y_app2 = app2.radiant_win_True\n",
    "X_app2 = app2.drop(labels=['radiant_win_True',\n",
    "                           'match_id'],axis=1)\n",
    "\n",
    "\n",
    "X_app2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train_app2, X_test_app2, y_train_app2, y_test_app2 = train_test_split(X_app2,y_app2,test_size=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standerizing the dataframe\n",
    "scale = StandardScaler()\n",
    "# fitting and transforming the train data set\n",
    "X_train_app2 = scale.fit_transform(X_train_app2)\n",
    "# transforming the test set\n",
    "X_test_app2 = scale.transform(X_test_app2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating summary score tables for model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approuch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary table for approuch one models\n",
    "summary_models_app1 = {'model':[],'Baseline':[],'train_score':[],'test_score':[],'cross_val_mean':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary tabele for approuch one ensamble methods\n",
    "summary_ensamble_app1 = {'ensamble':[],'Baseline':[],'train_score':[],'test_score':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking the baseline for approuch one to evaluate model performace \n",
    "baseline_app1 = y_app1.value_counts()[1]/len(y_app1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approuch 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary table for approuch one models\n",
    "summary_models_app2 = {'model':[],'Baseline':[],'train_score':[],'test_score':[],'cross_val_mean':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary tabele for approuch two ensamble methods\n",
    "summary_ensamble_app2 = {'ensamble':[],'Baseline':[],'train_score':[],'test_score':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking the baseline for approuch two to evaluate model performace \n",
    "baseline_app2 = y_app2.value_counts()[1]/len(y_app2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approuch one Gridsearch and Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch App 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree search parameters\n",
    "params_app1_dt = {'max_depth':np.arange(20,40),\n",
    "                 'criterion':['gini','entropy']}\n",
    "\n",
    "# LogisticR reggression search parameters\n",
    "params_app1_lr = {'penalty':['l1','l2']}\n",
    "\n",
    "# MLP Classifier search parameters\n",
    "params_app1_nnet = {'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    "                   'max_iter':[100,200]}\n",
    "\n",
    "# Nearist nighbor search parameters\n",
    "params_app1_knn = {'n_neighbors':np.arange(1,10)}\n",
    "\n",
    "\n",
    "# LinearSVC search parameters\n",
    "params_app1_svc = {'penalty':['l1','l2'],\n",
    "                  'max_iter':[1000,200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=20,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree gridsearch\n",
    "gr_dt = GridSearchCV(DecisionTreeClassifier(),params_app1_dt,cv=5,n_jobs=-1)\n",
    "# fitting the grid into approuch one\n",
    "gr_dt.fit(X_train_app1,y_train_app1)\n",
    "# displaying the best parameters\n",
    "gr_dt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic reggression gridsearch\n",
    "gr_lr = GridSearchCV(LogisticRegression(),params_app1_lr,cv=5,n_jobs=-1)\n",
    "# fitting the grid into approuch 1\n",
    "gr_lr.fit(X_train_app1,y_train_app1)\n",
    "# displaying the best parameters\n",
    "gr_lr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='identity', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 70, 50, 24, 10, 4),\n",
       "       learning_rate='constant', learning_rate_init=0.001, max_iter=200,\n",
       "       momentum=0.9, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLP Classifier gridsearch\n",
    "gr_nnet = GridSearchCV(MLPClassifier(hidden_layer_sizes=(100,70,50,24,10,4)),params_app1_nnet,cv=5,n_jobs=-1)\n",
    "# fitting the grid into approuch 1\n",
    "gr_nnet.fit(X_train_app1,y_train_app1)\n",
    "# displaying the best parameters\n",
    "gr_nnet.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nearist nighbor gridsearch\n",
    "gr_knn = GridSearchCV(KNeighborsClassifier(n_jobs=-1),params_app1_knn,cv=5,n_jobs=-1)\n",
    "# fitting the grid into approuch 1\n",
    "gr_knn.fit(X_train_app1,y_train_app1)\n",
    "# displaying the best parameters\n",
    "gr_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l1', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LinearSVC gridsearch\n",
    "gr_svc = GridSearchCV(LinearSVC(dual=False),params_app1_svc,cv=5,n_jobs=-1)\n",
    "# fitting the grid into approuch one\n",
    "gr_svc.fit(X_train_app1,y_train_app1)\n",
    "# displaying the best parameters\n",
    "gr_svc.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling App 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.6831078131820166\n",
      "---\n",
      "test score:  0.5339443312966734\n",
      "---\n",
      "cross val mean:  0.5293175038857105\n"
     ]
    }
   ],
   "source": [
    "# decision tree using the best parameters\n",
    "dt_app1 = DecisionTreeClassifier(criterion='gini',max_depth=20)\n",
    "# fitting approuch one data set\n",
    "dt_app1.fit(X_train_app1,y_train_app1)\n",
    "# obtaining cross val scores mean\n",
    "dt_app1_cvm = cross_val_score(dt_app1,X_train_app1,y_train_app1,cv=5).mean()\n",
    "# printing scores\n",
    "print('train score: ',dt_app1.score(X_train_app1,y_train_app1))\n",
    "print('---')\n",
    "print('test score: ',dt_app1.score(X_test_app1,y_test_app1))\n",
    "print('---')\n",
    "print('cross val mean: ',dt_app1_cvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting X test for model evaluation\n",
    "y_hat_dt_app1 = dt_app1.predict(X_test_app1)\n",
    "y_hat_dt_app1[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending scores and baseline in the summary table\n",
    "summary_models_app1['model'].append('Decision Tree')\n",
    "summary_models_app1['Baseline'].append(baseline_app1)\n",
    "summary_models_app1['train_score'].append(dt_app1.score(X_train_app1,y_train_app1))\n",
    "summary_models_app1['test_score'].append(dt_app1.score(X_test_app1,y_test_app1))\n",
    "summary_models_app1['cross_val_mean'].append(dt_app1_cvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avg_mmr</td>\n",
       "      <td>0.191236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>num_mmr</td>\n",
       "      <td>0.041522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tot_agi</td>\n",
       "      <td>0.020183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tot_range</td>\n",
       "      <td>0.017799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tot_intel</td>\n",
       "      <td>0.017382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature  importance\n",
       "0    avg_mmr    0.191236\n",
       "1    num_mmr    0.041522\n",
       "4    tot_agi    0.020183\n",
       "5  tot_range    0.017799\n",
       "2  tot_intel    0.017382"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying feature importance top 5\n",
    "dt_feat_app1 = pd.DataFrame(X_app1.columns,columns=['feature'])\n",
    "dt_feat_app1['importance'] = dt_app1.feature_importances_\n",
    "# displaying in assending orede\n",
    "dt_feat_app1.sort_values(by='importance',ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### most target affecting features are the ones shown above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Logistic Reggression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.5736214171395315\n",
      "---\n",
      "test score:  0.5667006109979633\n",
      "---\n",
      "cross val mean:  0.5536880452395911\n"
     ]
    }
   ],
   "source": [
    "# Logistic Reggression using the best parameters\n",
    "lr_app1 = LogisticRegression(penalty='l2')\n",
    "# fitting approuch one data set\n",
    "lr_app1.fit(X_train_app1,y_train_app1)\n",
    "# obtaining cross val scores mean\n",
    "lr_app1_cvm = cross_val_score(lr_app1,X_train_app1,y_train_app1,cv=5).mean()\n",
    "# printing scores\n",
    "print('train score: ',lr_app1.score(X_train_app1,y_train_app1))\n",
    "print('---')\n",
    "print('test score: ',lr_app1.score(X_test_app1,y_test_app1))\n",
    "print('---')\n",
    "print('cross val mean: ',lr_app1_cvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting X test for model evaluation\n",
    "y_hat_lr_app1 = lr_app1.predict(X_test_app1)\n",
    "y_hat_lr_app1[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending scores and baseline in the summary table\n",
    "summary_models_app1['model'].append('Logistic reggression')\n",
    "summary_models_app1['Baseline'].append(baseline_app1)\n",
    "summary_models_app1['train_score'].append(lr_app1.score(X_train_app1,y_train_app1))\n",
    "summary_models_app1['test_score'].append(lr_app1.score(X_test_app1,y_test_app1))\n",
    "summary_models_app1['cross_val_mean'].append(lr_app1_cvm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.5709297250109122\n",
      "---\n",
      "test score:  0.5609300746775289\n",
      "---\n",
      "cross val mean:  0.5502693872151857\n"
     ]
    }
   ],
   "source": [
    "# MLP Classifier using the best parameters\n",
    "nnet_app1 = MLPClassifier(hidden_layer_sizes=(100,70,50,24,10,4),max_iter=200,activation='identity')\n",
    "# fitting approuch one data set\n",
    "nnet_app1.fit(X_train_app1,y_train_app1)\n",
    "# obtaining cross val scores mean\n",
    "nnet_app1_cvm = cross_val_score(nnet_app1,X_train_app1,y_train_app1,cv=5).mean()\n",
    "# printing scores\n",
    "print('train score: ',nnet_app1.score(X_train_app1,y_train_app1))\n",
    "print('---')\n",
    "print('test score: ',nnet_app1.score(X_test_app1,y_test_app1))\n",
    "print('---')\n",
    "print('cross val mean: ',nnet_app1_cvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting X test for model evaluation\n",
    "y_hat_nnet_app1 = nnet_app1.predict(X_test_app1)\n",
    "y_hat_nnet_app1[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending scores and baseline in the summary table\n",
    "summary_models_app1['model'].append('MLP Classifier')\n",
    "summary_models_app1['Baseline'].append(baseline_app1)\n",
    "summary_models_app1['train_score'].append(nnet_app1.score(X_train_app1,y_train_app1))\n",
    "summary_models_app1['test_score'].append(nnet_app1.score(X_test_app1,y_test_app1))\n",
    "summary_models_app1['cross_val_mean'].append(nnet_app1_cvm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### KNearist Nighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.6960570347737524\n",
      "---\n",
      "test score:  0.5140868974881195\n",
      "---\n",
      "cross val mean:  0.5242973378749297\n"
     ]
    }
   ],
   "source": [
    "# KNN using the best parameters\n",
    "knn_app1 = KNeighborsClassifier(n_jobs=-1,n_neighbors=5)\n",
    "# fitting approuch one data set\n",
    "knn_app1.fit(X_train_app1,y_train_app1)\n",
    "# obtaining cross val scores mean\n",
    "knn_app1_cvm = cross_val_score(knn_app1,X_train_app1,y_train_app1,cv=5).mean()\n",
    "# printing scores\n",
    "print('train score: ',knn_app1.score(X_train_app1,y_train_app1))\n",
    "print('---')\n",
    "print('test score: ',knn_app1.score(X_test_app1,y_test_app1))\n",
    "print('---')\n",
    "print('cross val mean: ',knn_app1_cvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting X test for model evaluation\n",
    "y_hat_knn_app1 = knn_app1.predict(X_test_app1)\n",
    "y_hat_knn_app1[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending scores and baseline in the summary table\n",
    "summary_models_app1['model'].append('KNN')\n",
    "summary_models_app1['Baseline'].append(baseline_app1)\n",
    "summary_models_app1['train_score'].append(knn_app1.score(X_train_app1,y_train_app1))\n",
    "summary_models_app1['test_score'].append(knn_app1.score(X_test_app1,y_test_app1))\n",
    "summary_models_app1['cross_val_mean'].append(knn_app1_cvm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### LinearSVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.5736214171395315\n",
      "---\n",
      "test score:  0.5667006109979633\n",
      "---\n",
      "cross val mean:  0.5530333145937365\n"
     ]
    }
   ],
   "source": [
    "# LinearSVC using the best parameters\n",
    "svc_app1 = LinearSVC(max_iter=1000,penalty='l1',dual=False)\n",
    "# fitting approuch one data set\n",
    "svc_app1.fit(X_train_app1,y_train_app1)\n",
    "# obtaining cross val scores mean\n",
    "svc_app1_cvm = cross_val_score(svc_app1,X_train_app1,y_train_app1,cv=5).mean()\n",
    "# printing scores\n",
    "print('train score: ',svc_app1.score(X_train_app1,y_train_app1))\n",
    "print('---')\n",
    "print('test score: ',svc_app1.score(X_test_app1,y_test_app1))\n",
    "print('---')\n",
    "print('cross val mean: ',svc_app1_cvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting X test for model evaluation\n",
    "y_hat_svc_app1 = svc_app1.predict(X_test_app1)\n",
    "y_hat_svc_app1[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending scores and baseline in the summary table\n",
    "summary_models_app1['model'].append('SVC')\n",
    "summary_models_app1['Baseline'].append(baseline_app1)\n",
    "summary_models_app1['train_score'].append(svc_app1.score(X_train_app1,y_train_app1))\n",
    "summary_models_app1['test_score'].append(svc_app1.score(X_test_app1,y_test_app1))\n",
    "summary_models_app1['cross_val_mean'].append(svc_app1_cvm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensamble methods App 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Adabtive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.5718754546777244\n",
      "---\n",
      "test score:  0.5677189409368636\n"
     ]
    }
   ],
   "source": [
    "# adaBoosting the best performing model along with using its best parameters\n",
    "ada_app1 = AdaBoostClassifier(LogisticRegression(penalty='l2'))\n",
    "# Fitting approuch one dataset\n",
    "ada_app1.fit(X_train_app1,y_train_app1)\n",
    "# printing scores\n",
    "print('train score: ',ada_app1.score(X_train_app1,y_train_app1))\n",
    "print('---')\n",
    "print('test score: ',ada_app1.score(X_test_app1,y_test_app1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting X test for model evaluation\n",
    "y_hat_ada_app1 = ada_app1.predict(X_test_app1)\n",
    "y_hat_ada_app1[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending the scores and baseline\n",
    "summary_ensamble_app1['ensamble'].append('AdaBoost')\n",
    "summary_ensamble_app1['Baseline'].append(baseline_app1)\n",
    "summary_ensamble_app1['train_score'].append(ada_app1.score(X_train_app1,y_train_app1))\n",
    "summary_ensamble_app1['test_score'].append(ada_app1.score(X_test_app1,y_test_app1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Extra Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.8673796013385712\n",
      "---\n",
      "test score:  0.5390359809911744\n"
     ]
    }
   ],
   "source": [
    "# ExtraTreeClasifier\n",
    "ext_app1 = ExtraTreesClassifier(n_jobs=-1,max_depth=20)\n",
    "# Fitting approuch one dataset\n",
    "ext_app1.fit(X_train_app1,y_train_app1)\n",
    "# printing scores\n",
    "print('train score: ',ext_app1.score(X_train_app1,y_train_app1))\n",
    "print('---')\n",
    "print('test score: ',ext_app1.score(X_test_app1,y_test_app1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra tree overfitted the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting X test for model evaluation\n",
    "y_hat_ext_app1 = ext_app1.predict(X_test_app1)\n",
    "y_hat_ext_app1[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending the scores and baseline\n",
    "summary_ensamble_app1['ensamble'].append('ExtraTreeClassifier')\n",
    "summary_ensamble_app1['Baseline'].append(baseline_app1)\n",
    "summary_ensamble_app1['train_score'].append(ext_app1.score(X_train_app1,y_train_app1))\n",
    "summary_ensamble_app1['test_score'].append(ext_app1.score(X_test_app1,y_test_app1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avg_mmr</td>\n",
       "      <td>0.029816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>num_mmr</td>\n",
       "      <td>0.026770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tot_agi</td>\n",
       "      <td>0.023588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tot_melee</td>\n",
       "      <td>0.019984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tot_intel</td>\n",
       "      <td>0.019969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature  importance\n",
       "0    avg_mmr    0.029816\n",
       "1    num_mmr    0.026770\n",
       "4    tot_agi    0.023588\n",
       "6  tot_melee    0.019984\n",
       "2  tot_intel    0.019969"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying feature importance top 5\n",
    "ext_feat_app1 = pd.DataFrame(X_app1.columns,columns=['feature'])\n",
    "ext_feat_app1['importance'] = ext_app1.feature_importances_\n",
    "# displaying in assending orede\n",
    "ext_feat_app1.sort_values(by='importance',ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### simular to decsion tree feature importance variables, seams like rank info and type totals have the most affect in predicting the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.8068529026625928\n",
      "---\n",
      "test score:  0.5381873727087576\n"
     ]
    }
   ],
   "source": [
    "# Random forest\n",
    "forest_app1 = RandomForestClassifier(n_jobs=-1,max_depth=20)\n",
    "# Fitting approuch one dataset\n",
    "forest_app1.fit(X_train_app1,y_train_app1)\n",
    "# printing scores\n",
    "print('train score: ',forest_app1.score(X_train_app1,y_train_app1))\n",
    "print('---')\n",
    "print('test score: ',forest_app1.score(X_test_app1,y_test_app1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forest also overfited the data or choise poor split point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting X test for model evaluation\n",
    "y_hat_forest_app1 = forest_app1.predict(X_test_app1)\n",
    "y_hat_forest_app1[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending the scores and baseline\n",
    "summary_ensamble_app1['ensamble'].append('RandomForest')\n",
    "summary_ensamble_app1['Baseline'].append(baseline_app1)\n",
    "summary_ensamble_app1['train_score'].append(forest_app1.score(X_train_app1,y_train_app1))\n",
    "summary_ensamble_app1['test_score'].append(forest_app1.score(X_test_app1,y_test_app1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avg_mmr</td>\n",
       "      <td>0.096548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>num_mmr</td>\n",
       "      <td>0.042423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tot_agi</td>\n",
       "      <td>0.033921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tot_stren</td>\n",
       "      <td>0.026363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tot_intel</td>\n",
       "      <td>0.025602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature  importance\n",
       "0    avg_mmr    0.096548\n",
       "1    num_mmr    0.042423\n",
       "4    tot_agi    0.033921\n",
       "3  tot_stren    0.026363\n",
       "2  tot_intel    0.025602"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying feature importance top 5\n",
    "forest_feat_app1 = pd.DataFrame(X_app1.columns,columns=['feature'])\n",
    "forest_feat_app1['importance'] = forest_app1.feature_importances_\n",
    "# displaying in assending orede\n",
    "forest_feat_app1.sort_values(by='importance',ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.5716572093699985\n",
      "---\n",
      "test score:  0.564663951120163\n"
     ]
    }
   ],
   "source": [
    "# bagging the best performing model along with using its best parameters\n",
    "bag_app1 = BaggingClassifier(base_estimator=LogisticRegression(penalty='l2'),n_jobs=-1)\n",
    "# Fitting approuch one dataset\n",
    "bag_app1.fit(X_train_app1,y_train_app1)\n",
    "# printing scores\n",
    "print('train score: ',bag_app1.score(X_train_app1,y_train_app1))\n",
    "print('---')\n",
    "print('test score: ',bag_app1.score(X_test_app1,y_test_app1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting X test for model evaluation\n",
    "y_hat_bag_app1 = bag_app1.predict(X_test_app1)\n",
    "y_hat_bag_app1[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending the scores and baseline\n",
    "summary_ensamble_app1['ensamble'].append('Bagging')\n",
    "summary_ensamble_app1['Baseline'].append(baseline_app1)\n",
    "summary_ensamble_app1['train_score'].append(forest_app1.score(X_train_app1,y_train_app1))\n",
    "summary_ensamble_app1['test_score'].append(forest_app1.score(X_test_app1,y_test_app1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approuch Two Gridsearch and Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch App 2\n",
    "finding the best parameters for the choicen models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree search parameters\n",
    "params_app2_dt = {'max_depth':np.arange(10,20),\n",
    "                 'criterion':['gini','entropy']}\n",
    "\n",
    "# LogisticR reggression search parameters\n",
    "params_app2_lr = {'penalty':['l1','l2']}\n",
    "\n",
    "# MLP Classifier search parameters\n",
    "params_app2_nnet = {'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    "                   'max_iter':[100,200]}\n",
    "\n",
    "# LinearSVC search parameters\n",
    "params_app2_svc = {'penalty':['l1','l2'],\n",
    "                  'max_iter':[1000,200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=19,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree gridsearch\n",
    "gr_dt_app2 = GridSearchCV(DecisionTreeClassifier(),params_app2_dt,cv=5,n_jobs=-1)\n",
    "# fitting the grid into approuch one\n",
    "gr_dt_app2.fit(X_train_app2,y_train_app2)\n",
    "# displaying the best parameters\n",
    "gr_dt_app2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression gridsearch\n",
    "gr_lr_app2 = GridSearchCV(LogisticRegression(),params_app2_lr,cv=5,n_jobs=-1)\n",
    "# fitting the grid into approuch one\n",
    "gr_lr_app2.fit(X_train_app2,y_train_app2)\n",
    "# displaying the best parameters\n",
    "gr_lr_app2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sultan.almuhanna/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='identity', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 70, 50, 24), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLP Classifeir gridsearch\n",
    "gr_nnet_app2 = GridSearchCV(MLPClassifier(hidden_layer_sizes=(100,70,50,24)),params_app2_nnet,cv=5,n_jobs=-1)\n",
    "# fitting the grid into approuch one\n",
    "gr_nnet_app2.fit(X_train_app2,y_train_app2)\n",
    "# displaying the best parameters\n",
    "gr_nnet_app2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LinearSVC gridsearch\n",
    "gr_svc_app2 = GridSearchCV(LinearSVC(dual=False),params_app2_svc,cv=5,n_jobs=-1)\n",
    "# fitting the grid into approuch one\n",
    "gr_svc_app2.fit(X_train_app2,y_train_app2)\n",
    "# displaying the best parameters\n",
    "gr_svc_app2.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling App 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.5885348465008002\n",
      "---\n",
      "test score:  0.5336048879837068\n",
      "---\n",
      "cross val mean:  0.5346283144283872\n"
     ]
    }
   ],
   "source": [
    "# decision tree using the best parameters\n",
    "dt_app2 = DecisionTreeClassifier(criterion='gini',max_depth=19)\n",
    "# fitting approuch two data set\n",
    "dt_app2.fit(X_train_app2,y_train_app2)\n",
    "# obtaining cross val scores mean\n",
    "dt_app2_cvm = cross_val_score(dt_app2,X_train_app2,y_train_app2,cv=5).mean()\n",
    "# printing scores\n",
    "print('train score: ',dt_app2.score(X_train_app2,y_train_app2))\n",
    "print('---')\n",
    "print('test score: ',dt_app2.score(X_test_app2,y_test_app2))\n",
    "print('---')\n",
    "print('cross val mean: ',dt_app2_cvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting X test for model evaluation\n",
    "y_hat_dt_app2 = dt_app2.predict(X_test_app2)\n",
    "y_hat_dt_app2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending scores and baseline in the summary table\n",
    "summary_models_app2['model'].append('Decision Tree')\n",
    "summary_models_app2['Baseline'].append(baseline_app2)\n",
    "summary_models_app2['train_score'].append(dt_app2.score(X_train_app2,y_train_app2))\n",
    "summary_models_app2['test_score'].append(dt_app2.score(X_test_app2,y_test_app2))\n",
    "summary_models_app2['cross_val_mean'].append(dt_app2_cvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avg_mmr</td>\n",
       "      <td>0.100782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>diff_intel</td>\n",
       "      <td>0.024012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>diff_agi</td>\n",
       "      <td>0.017012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>dire_plyr_5_Io</td>\n",
       "      <td>0.017008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>dire_plyr_1_Necrophos</td>\n",
       "      <td>0.014516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature  importance\n",
       "0                  avg_mmr    0.100782\n",
       "1               diff_intel    0.024012\n",
       "3                 diff_agi    0.017012\n",
       "495         dire_plyr_5_Io    0.017008\n",
       "65   dire_plyr_1_Necrophos    0.014516"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying feature importance top 5\n",
    "dt_feat_app2 = pd.DataFrame(X_app2.columns,columns=['feature'])\n",
    "dt_feat_app2['importance'] = dt_app2.feature_importances_\n",
    "# displaying in assending orede\n",
    "dt_feat_app2.sort_values(by='importance',ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### in feature importance in approuch two the most important features ware the average rank of the match and two diffrence between teams types along with some player hero selctions wich is diffrent from the first approuch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.6521897279208497\n",
      "---\n",
      "test score:  0.551255940257977\n",
      "---\n",
      "cross val mean:  0.5575430139885578\n"
     ]
    }
   ],
   "source": [
    "# Logistic Reggression using the best parameters\n",
    "lr_app2 = LogisticRegression(penalty='l1')\n",
    "# fitting approuch one data set\n",
    "lr_app2.fit(X_train_app2,y_train_app2)\n",
    "# obtaining cross val scores mean\n",
    "lr_app2_cvm = cross_val_score(lr_app2,X_train_app2,y_train_app2,cv=5).mean()\n",
    "# printing scores\n",
    "print('train score: ',lr_app2.score(X_train_app2,y_train_app2))\n",
    "print('---')\n",
    "print('test score: ',lr_app2.score(X_test_app2,y_test_app2))\n",
    "print('---')\n",
    "print('cross val mean: ',lr_app2_cvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting X test for model evaluation\n",
    "y_hat_lr_app2 = lr_app2.predict(X_test_app2)\n",
    "y_hat_lr_app2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending scores and baseline in the summary table\n",
    "summary_models_app2['model'].append('Logistic Regreassion')\n",
    "summary_models_app2['Baseline'].append(baseline_app2)\n",
    "summary_models_app2['train_score'].append(lr_app2.score(X_train_app2,y_train_app2))\n",
    "summary_models_app2['test_score'].append(lr_app2.score(X_test_app2,y_test_app2))\n",
    "summary_models_app2['cross_val_mean'].append(lr_app2_cvm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.6452058780736214\n",
      "---\n",
      "test score:  0.5521045485403937\n",
      "---\n",
      "cross val mean:  0.5539777902708424\n"
     ]
    }
   ],
   "source": [
    "# MLP Classifier using the best parameters\n",
    "nnet_app2 = MLPClassifier(hidden_layer_sizes=(100,70,50,24),max_iter=200,activation='identity')\n",
    "# fitting approuch one data set\n",
    "nnet_app2.fit(X_train_app2,y_train_app2)\n",
    "# obtaining cross val scores mean\n",
    "nnet_app2_cvm = cross_val_score(nnet_app2,X_train_app2,y_train_app2,cv=5).mean()\n",
    "# printing scores\n",
    "print('train score: ',nnet_app2.score(X_train_app2,y_train_app2))\n",
    "print('---')\n",
    "print('test score: ',nnet_app2.score(X_test_app2,y_test_app2))\n",
    "print('---')\n",
    "print('cross val mean: ',nnet_app2_cvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting X test for model evaluation\n",
    "y_hat_nnet_app2 = nnet_app2.predict(X_test_app2)\n",
    "y_hat_nnet_app2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending scores and baseline in the summary table\n",
    "summary_models_app2['model'].append('MLP Classifier')\n",
    "summary_models_app2['Baseline'].append(baseline_app2)\n",
    "summary_models_app2['train_score'].append(nnet_app2.score(X_train_app2,y_train_app2))\n",
    "summary_models_app2['test_score'].append(nnet_app2.score(X_test_app2,y_test_app2))\n",
    "summary_models_app2['cross_val_mean'].append(nnet_app2_cvm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Knearist nighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.7589116833988069\n",
      "---\n",
      "test score:  0.5044127630685675\n",
      "---\n",
      "cross val mean:  0.5109844373160489\n"
     ]
    }
   ],
   "source": [
    "# KNN using the best parameters\n",
    "knn_app2 = KNeighborsClassifier(n_jobs=-1,n_neighbors=3)\n",
    "# fitting approuch one data set\n",
    "knn_app2.fit(X_train_app2,y_train_app2)\n",
    "# obtaining cross val scores mean\n",
    "knn_app2_cvm = cross_val_score(knn_app2,X_train_app2,y_train_app2,cv=5).mean()\n",
    "# printing scores\n",
    "print('train score: ',knn_app2.score(X_train_app2,y_train_app2))\n",
    "print('---')\n",
    "print('test score: ',knn_app2.score(X_test_app2,y_test_app2))\n",
    "print('---')\n",
    "print('cross val mean: ',knn_app2_cvm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearist nighbor also overfit the training set ending up with a poor score for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting X test for model evaluation\n",
    "y_hat_knn_app2 = knn_app2.predict(X_test_app2)\n",
    "y_hat_knn_app2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending scores and baseline in the summary table\n",
    "summary_models_app2['model'].append('KNN')\n",
    "summary_models_app2['Baseline'].append(baseline_app2)\n",
    "summary_models_app2['train_score'].append(knn_app2.score(X_train_app2,y_train_app2))\n",
    "summary_models_app2['test_score'].append(knn_app2.score(X_test_app2,y_test_app2))\n",
    "summary_models_app2['cross_val_mean'].append(knn_app2_cvm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### LinearCVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.5908627964498764\n",
      "---\n",
      "test score:  0.5327562797012899\n",
      "---\n",
      "cross val mean:  0.5376835212804656\n"
     ]
    }
   ],
   "source": [
    "# LinearSVC using the best parameters\n",
    "svc_app2 = LinearSVC(max_iter=1000,penalty='l2')\n",
    "# fitting approuch one data set\n",
    "svc_app2.fit(X_train_app2,y_train_app2)\n",
    "# obtaining cross val scores mean\n",
    "svc_app2_cvm = cross_val_score(svc_app2,X_train_app2,y_train_app2,cv=5).mean()\n",
    "# printing scores\n",
    "print('train score: ',svc_app2.score(X_train_app2,y_train_app2))\n",
    "print('---')\n",
    "print('test score: ',svc_app2.score(X_test_app2,y_test_app2))\n",
    "print('---')\n",
    "print('cross val mean: ',svc_app2_cvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting X test for model evaluation\n",
    "y_hat_svc_app2 = svc_app2.predict(X_test_app2)\n",
    "y_hat_svc_app2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending scores and baseline in the summary table\n",
    "summary_models_app2['model'].append('SVC')\n",
    "summary_models_app2['Baseline'].append(baseline_app2)\n",
    "summary_models_app2['train_score'].append(svc_app2.score(X_train_app2,y_train_app2))\n",
    "summary_models_app2['test_score'].append(svc_app2.score(X_test_app2,y_test_app2))\n",
    "summary_models_app2['cross_val_mean'].append(svc_app2_cvm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensamble methods App 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Adabtive boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.6476793248945147\n",
      "---\n",
      "test score:  0.5502376103190767\n"
     ]
    }
   ],
   "source": [
    "# adaBoosting the best performing model along with using its best parameters\n",
    "ada_app2 = AdaBoostClassifier(LogisticRegression(penalty='l2'))\n",
    "# Fitting approuch one dataset\n",
    "ada_app2.fit(X_train_app2,y_train_app2)\n",
    "# printing scores\n",
    "print('train score: ',ada_app2.score(X_train_app2,y_train_app2))\n",
    "print('---')\n",
    "print('test score: ',ada_app2.score(X_test_app2,y_test_app2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting X test for model evaluation\n",
    "y_hat_ada_app2 = ada_app2.predict(X_test_app2)\n",
    "y_hat_ada_app2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending the scores and baseline\n",
    "summary_ensamble_app2['ensamble'].append('AdaBoost')\n",
    "summary_ensamble_app2['Baseline'].append(baseline_app2)\n",
    "summary_ensamble_app2['train_score'].append(ada_app2.score(X_train_app2,y_train_app2))\n",
    "summary_ensamble_app2['test_score'].append(ada_app2.score(X_test_app2,y_test_app2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Extra Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.6525534701003929\n",
      "---\n",
      "test score:  0.5358112695179905\n"
     ]
    }
   ],
   "source": [
    "# ExtraTreeClasifier\n",
    "ext_app2 = ExtraTreesClassifier(n_jobs=-1,max_depth=19)\n",
    "# Fitting approuch one dataset\n",
    "ext_app2.fit(X_train_app2,y_train_app2)\n",
    "# printing scores\n",
    "print('train score: ',ext_app2.score(X_train_app2,y_train_app2))\n",
    "print('---')\n",
    "print('test score: ',ext_app2.score(X_test_app2,y_test_app2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting X test for model evaluation\n",
    "y_hat_ext_app2 = ext_app2.predict(X_test_app2)\n",
    "y_hat_ext_app2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending the scores and baseline\n",
    "summary_ensamble_app2['ensamble'].append('ExtraTreeClassifier')\n",
    "summary_ensamble_app2['Baseline'].append(baseline_app2)\n",
    "summary_ensamble_app2['train_score'].append(ext_app2.score(X_train_app2,y_train_app2))\n",
    "summary_ensamble_app2['test_score'].append(ext_app2.score(X_test_app2,y_test_app2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>dire_plyr_1_Necrophos</td>\n",
       "      <td>0.013763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>dire_plyr_3_Nature's Prophet</td>\n",
       "      <td>0.011663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>rad_plyr_4_Silencer</td>\n",
       "      <td>0.010684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>dire_plyr_5_Io</td>\n",
       "      <td>0.009695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>dire_plyr_1_Enchantress</td>\n",
       "      <td>0.008956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          feature  importance\n",
       "65          dire_plyr_1_Necrophos    0.013763\n",
       "290  dire_plyr_3_Nature's Prophet    0.011663\n",
       "990           rad_plyr_4_Silencer    0.010684\n",
       "495                dire_plyr_5_Io    0.009695\n",
       "37        dire_plyr_1_Enchantress    0.008956"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying feature importance top 5\n",
    "ext_feat_app2 = pd.DataFrame(X_app2.columns,columns=['feature'])\n",
    "ext_feat_app2['importance'] = ext_app2.feature_importances_\n",
    "# displaying in assending orede\n",
    "ext_feat_app2.sort_values(by='importance',ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### for the extra tree classifier looks like the affecting features are hero picks, but due to resualts that are near the baseline these heros wont be consedered as the most affecting picks for matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.6695766041030118\n",
      "---\n",
      "test score:  0.5269857433808554\n"
     ]
    }
   ],
   "source": [
    "# Random forest\n",
    "forest_app2 = RandomForestClassifier(n_jobs=-1,max_depth=19)\n",
    "# Fitting approuch one dataset\n",
    "forest_app2.fit(X_train_app2,y_train_app2)\n",
    "# printing scores\n",
    "print('train score: ',forest_app2.score(X_train_app2,y_train_app2))\n",
    "print('---')\n",
    "print('test score: ',forest_app2.score(X_test_app2,y_test_app2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting X test for model evaluation\n",
    "y_hat_forest_app2 = forest_app2.predict(X_test_app2)\n",
    "y_hat_forest_app2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending the scores and baseline\n",
    "summary_ensamble_app2['ensamble'].append('RandomForest')\n",
    "summary_ensamble_app2['Baseline'].append(baseline_app2)\n",
    "summary_ensamble_app2['train_score'].append(forest_app2.score(X_train_app2,y_train_app2))\n",
    "summary_ensamble_app2['test_score'].append(forest_app2.score(X_test_app2,y_test_app2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avg_mmr</td>\n",
       "      <td>0.038094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>diff_agi</td>\n",
       "      <td>0.011280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>diff_range</td>\n",
       "      <td>0.010899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>diff_melee</td>\n",
       "      <td>0.010515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>diff_intel</td>\n",
       "      <td>0.008737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  importance\n",
       "0     avg_mmr    0.038094\n",
       "3    diff_agi    0.011280\n",
       "4  diff_range    0.010899\n",
       "5  diff_melee    0.010515\n",
       "1  diff_intel    0.008737"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying feature importance top 5\n",
    "forest_feat_app2 = pd.DataFrame(X_app2.columns,columns=['feature'])\n",
    "forest_feat_app2['importance'] = forest_app2.feature_importances_\n",
    "# displaying in assending orede\n",
    "forest_feat_app2.sort_values(by='importance',ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.6514622435617634\n",
      "---\n",
      "test score:  0.5504073319755601\n"
     ]
    }
   ],
   "source": [
    "# bagging the best performing model along with using its best parameters\n",
    "bag_app2 = BaggingClassifier(base_estimator=LogisticRegression(penalty='l2'),n_jobs=-1)\n",
    "# Fitting approuch one dataset\n",
    "bag_app2.fit(X_train_app2,y_train_app2)\n",
    "# printing scores\n",
    "print('train score: ',bag_app2.score(X_train_app2,y_train_app2))\n",
    "print('---')\n",
    "print('test score: ',bag_app2.score(X_test_app2,y_test_app2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting X test for model evaluation\n",
    "y_hat_bag_app2 = bag_app2.predict(X_test_app2)\n",
    "y_hat_bag_app2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending the scores and baseline\n",
    "summary_ensamble_app2['ensamble'].append('Bagging')\n",
    "summary_ensamble_app2['Baseline'].append(baseline_app2)\n",
    "summary_ensamble_app2['train_score'].append(bag_app2.score(X_train_app2,y_train_app2))\n",
    "summary_ensamble_app2['test_score'].append(bag_app2.score(X_test_app2,y_test_app2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approuch 1 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### printing the classification report of the best performing models in approuch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Baseline</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>cross_val_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.532284</td>\n",
       "      <td>0.683108</td>\n",
       "      <td>0.533944</td>\n",
       "      <td>0.529318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic reggression</td>\n",
       "      <td>0.532284</td>\n",
       "      <td>0.573621</td>\n",
       "      <td>0.566701</td>\n",
       "      <td>0.553688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic reggression</td>\n",
       "      <td>0.532284</td>\n",
       "      <td>0.573621</td>\n",
       "      <td>0.566701</td>\n",
       "      <td>0.553688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP Classifier</td>\n",
       "      <td>0.532284</td>\n",
       "      <td>0.570930</td>\n",
       "      <td>0.560930</td>\n",
       "      <td>0.550269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.532284</td>\n",
       "      <td>0.696057</td>\n",
       "      <td>0.514087</td>\n",
       "      <td>0.524297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.532284</td>\n",
       "      <td>0.573621</td>\n",
       "      <td>0.566701</td>\n",
       "      <td>0.553033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  Baseline  train_score  test_score  cross_val_mean\n",
       "0         Decision Tree  0.532284     0.683108    0.533944        0.529318\n",
       "1  Logistic reggression  0.532284     0.573621    0.566701        0.553688\n",
       "2  Logistic reggression  0.532284     0.573621    0.566701        0.553688\n",
       "3        MLP Classifier  0.532284     0.570930    0.560930        0.550269\n",
       "4                   KNN  0.532284     0.696057    0.514087        0.524297\n",
       "5                   SVC  0.532284     0.573621    0.566701        0.553033"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first by converting the summary table from a dictionary to a dataframe for models\n",
    "# displaying the summary table\n",
    "summary_models_app1 = pd.DataFrame(summary_models_app1)\n",
    "summary_models_app1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Logistic Regression, MLP classifier and support vector classfier performed better than the other models for approuch 1 with approximatly 3 percent. and the three mentioned models performed better than the baseline, not that much but its an improvement with almost also 3 percent. Lastly those three models predictions will be used for the classification reports and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression classification report\n",
      "---\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.42      0.47      2745\n",
      "          1       0.58      0.70      0.63      3147\n",
      "\n",
      "avg / total       0.56      0.57      0.56      5892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report for logistic reggression\n",
    "from sklearn.metrics import classification_report\n",
    "print('Logistic Regression classification report')\n",
    "print('---')\n",
    "print(classification_report(y_test_app1,y_hat_lr_app1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier classification report\n",
      "---\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.44      0.48      2745\n",
      "          1       0.58      0.67      0.62      3147\n",
      "\n",
      "avg / total       0.56      0.56      0.56      5892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report for MLP Classifir\n",
    "print('MLP Classifier classification report')\n",
    "print('---')\n",
    "print(classification_report(y_test_app1,y_hat_nnet_app1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC classification report\n",
      "---\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.41      0.47      2745\n",
      "          1       0.58      0.70      0.63      3147\n",
      "\n",
      "avg / total       0.56      0.57      0.56      5892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report for LinearSVC\n",
    "print('LinearSVC classification report')\n",
    "print('---')\n",
    "print(classification_report(y_test_app1,y_hat_svc_app1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### classification reports for model resaults are simular to each other for approuch one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Displaying the confusion matrix to see the correctly and incorrectly classified instences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic confusion matrix\n",
      "----\n",
      "[[1143 1602]\n",
      " [ 951 2196]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print('Logistic confusion matrix')\n",
    "print('----')\n",
    "print(confusion_matrix(y_test_app1,y_hat_lr_app1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP confusion matrix\n",
      "----\n",
      "[[1205 1540]\n",
      " [1047 2100]]\n"
     ]
    }
   ],
   "source": [
    "print('MLP confusion matrix')\n",
    "print('----')\n",
    "print(confusion_matrix(y_test_app1,y_hat_nnet_app1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC confusion matrix\n",
      "----\n",
      "[[1139 1606]\n",
      " [ 947 2200]]\n"
     ]
    }
   ],
   "source": [
    "print('SVC confusion matrix')\n",
    "print('----')\n",
    "print(confusion_matrix(y_test_app1,y_hat_svc_app1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### printing the classification report of the best performing Ensamble method in approuch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ensamble</th>\n",
       "      <th>Baseline</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.532284</td>\n",
       "      <td>0.571875</td>\n",
       "      <td>0.567719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.532284</td>\n",
       "      <td>0.571875</td>\n",
       "      <td>0.567719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>0.532284</td>\n",
       "      <td>0.867380</td>\n",
       "      <td>0.539036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.532284</td>\n",
       "      <td>0.806853</td>\n",
       "      <td>0.538187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.532284</td>\n",
       "      <td>0.806853</td>\n",
       "      <td>0.538187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.532284</td>\n",
       "      <td>0.806853</td>\n",
       "      <td>0.538187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ensamble  Baseline  train_score  test_score\n",
       "0             AdaBoost  0.532284     0.571875    0.567719\n",
       "1             AdaBoost  0.532284     0.571875    0.567719\n",
       "2  ExtraTreeClassifier  0.532284     0.867380    0.539036\n",
       "3         RandomForest  0.532284     0.806853    0.538187\n",
       "4         RandomForest  0.532284     0.806853    0.538187\n",
       "5              Bagging  0.532284     0.806853    0.538187"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first by converting the summary table from a dictionary to a dataframe for ensamble methods\n",
    "summary_ensamble_app1 = pd.DataFrame(summary_ensamble_app1)\n",
    "summary_ensamble_app1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Logistic Regression Boosted using Adabditve boosting performed better than the other ensamble methods for approuch 1 with approximatly 3 percent. the othe methods overfitted on the training data while performed poorly on the test set and the method performed better than the baseline, not that much but its an improvement with almost also 3 percent.  Moreover the evaluation will include only the Logistic regression boosted and the boosted logistic model performed better than the Logistic model by small percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBtive Boosting classification report\n",
      "---\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.42      0.47      2745\n",
      "          1       0.58      0.70      0.63      3147\n",
      "\n",
      "avg / total       0.56      0.57      0.56      5892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report for MLP Classifir\n",
    "print('AdaBtive Boosting classification report')\n",
    "print('---')\n",
    "print(classification_report(y_test_app1,y_hat_ada_app1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### scores did not show much change from the original Logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boosted Logistic confusion matrix\n",
      "----\n",
      "[[1142 1603]\n",
      " [ 944 2203]]\n"
     ]
    }
   ],
   "source": [
    "print('Boosted Logistic confusion matrix')\n",
    "print('----')\n",
    "print(confusion_matrix(y_test_app1,y_hat_ada_app1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approuch 2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Baseline</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>cross_val_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.532284</td>\n",
       "      <td>0.588535</td>\n",
       "      <td>0.533605</td>\n",
       "      <td>0.534628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regreassion</td>\n",
       "      <td>0.532284</td>\n",
       "      <td>0.652190</td>\n",
       "      <td>0.551256</td>\n",
       "      <td>0.557543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP Classifier</td>\n",
       "      <td>0.532284</td>\n",
       "      <td>0.645206</td>\n",
       "      <td>0.552105</td>\n",
       "      <td>0.553978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.532284</td>\n",
       "      <td>0.758912</td>\n",
       "      <td>0.504413</td>\n",
       "      <td>0.510984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.532284</td>\n",
       "      <td>0.590863</td>\n",
       "      <td>0.532756</td>\n",
       "      <td>0.537684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.532284</td>\n",
       "      <td>0.590863</td>\n",
       "      <td>0.532756</td>\n",
       "      <td>0.537684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  Baseline  train_score  test_score  cross_val_mean\n",
       "0         Decision Tree  0.532284     0.588535    0.533605        0.534628\n",
       "1  Logistic Regreassion  0.532284     0.652190    0.551256        0.557543\n",
       "2        MLP Classifier  0.532284     0.645206    0.552105        0.553978\n",
       "3                   KNN  0.532284     0.758912    0.504413        0.510984\n",
       "4                   SVC  0.532284     0.590863    0.532756        0.537684\n",
       "5                   SVC  0.532284     0.590863    0.532756        0.537684"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first by converting the summary table from a dictionary to a dataframe for models\n",
    "# displaying the summary table\n",
    "summary_models_app2 = pd.DataFrame(summary_models_app2)\n",
    "summary_models_app2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### only Logistic reggression and MLP classifier performed better the baseline by 2 percent wich is an improvment along with performing better than the other used models. knn overfitted on the training data set, for the evaluation only the two mentioned models will be used for classification report and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression classification report\n",
      "---\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.47      0.50      2790\n",
      "          1       0.57      0.62      0.59      3102\n",
      "\n",
      "avg / total       0.55      0.55      0.55      5892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression classification report')\n",
    "print('---')\n",
    "print(classification_report(y_test_app2,y_hat_lr_app2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier classification report\n",
      "---\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.43      0.47      2790\n",
      "          1       0.56      0.67      0.61      3102\n",
      "\n",
      "avg / total       0.55      0.55      0.55      5892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('MLP Classifier classification report')\n",
    "print('---')\n",
    "print(classification_report(y_test_app2,y_hat_nnet_app2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Checking the confusion matrices for both Logistic and MLP classifier models to see the correctly and incorrecly classified instences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic  Model confusion matrix\n",
      "----\n",
      "[[1314 1476]\n",
      " [1168 1934]]\n"
     ]
    }
   ],
   "source": [
    "print('Logistic  Model confusion matrix')\n",
    "print('----')\n",
    "print(confusion_matrix(y_test_app2,y_hat_lr_app2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier confusion matrix\n",
      "----\n",
      "[[1186 1604]\n",
      " [1035 2067]]\n"
     ]
    }
   ],
   "source": [
    "print('MLP Classifier confusion matrix')\n",
    "print('----')\n",
    "print(confusion_matrix(y_test_app2,y_hat_nnet_app2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### printing the classification report of the best performing Ensamble method in Approuch 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ensamble</th>\n",
       "      <th>Baseline</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.532284</td>\n",
       "      <td>0.647679</td>\n",
       "      <td>0.550238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>0.532284</td>\n",
       "      <td>0.652553</td>\n",
       "      <td>0.535811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.532284</td>\n",
       "      <td>0.669577</td>\n",
       "      <td>0.526986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.532284</td>\n",
       "      <td>0.651462</td>\n",
       "      <td>0.550407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ensamble  Baseline  train_score  test_score\n",
       "0             AdaBoost  0.532284     0.647679    0.550238\n",
       "1  ExtraTreeClassifier  0.532284     0.652553    0.535811\n",
       "2         RandomForest  0.532284     0.669577    0.526986\n",
       "3              Bagging  0.532284     0.651462    0.550407"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first by converting the summary table from a dictionary to a dataframe for ensamble methods\n",
    "summary_ensamble_app2 = pd.DataFrame(summary_ensamble_app2)\n",
    "summary_ensamble_app2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### bagging and Boosting using Logistic reggression ware the best ensamble methods used in approuch 2, performing better than the baseline by 2 percent and better the models with approximitly 3 percent wich is an improvment. those mentioned ensamble methods will be used for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBtive Boosting classification report\n",
      "---\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.47      0.50      2790\n",
      "          1       0.57      0.62      0.59      3102\n",
      "\n",
      "avg / total       0.55      0.55      0.55      5892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report for adabtive boosting\n",
    "print('AdaBtive Boosting classification report')\n",
    "print('---')\n",
    "print(classification_report(y_test_app2,y_hat_ada_app2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bagging classification report\n",
      "---\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.47      0.50      2790\n",
      "          1       0.57      0.62      0.59      3102\n",
      "\n",
      "avg / total       0.55      0.55      0.55      5892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report forBagging\n",
    "print('bagging classification report')\n",
    "print('---')\n",
    "print(classification_report(y_test_app2,y_hat_bag_app2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Checking the confusion matrices for both boosted Logistic and bagged Logistic ensamble methods for approuch 2 to see the correctly and incorrecly classified instences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boosted Logistic confusion matrix\n",
      "----\n",
      "[[1142 1603]\n",
      " [ 944 2203]]\n"
     ]
    }
   ],
   "source": [
    "print('Boosted Logistic confusion matrix')\n",
    "print('----')\n",
    "print(confusion_matrix(y_test_app1,y_hat_ada_app1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagged Logistic confusion matrix\n",
      "----\n",
      "[[1122 1623]\n",
      " [ 942 2205]]\n"
     ]
    }
   ],
   "source": [
    "print('Bagged Logistic confusion matrix')\n",
    "print('----')\n",
    "print(confusion_matrix(y_test_app1,y_hat_bag_app1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model  Evaluation\n",
    "regarding the approuches used in this project, approuch 1 wich was each match combined into two observations that describe each team hero picks and taking the hero types and attack type total for each regardless of the hero pick position. approuch 1 performed in modeling and ensambling better than approuch two wich contains all match pick including hero pick postioning and taking the diffrence in each team for the total types and attack types. performed better by 1 percent for the best models in both approuches wich is also an improvment from the baseline, for the final model choice approuch one Boosted Logistic regression model that their parameters ware takien from a gridsearch."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
